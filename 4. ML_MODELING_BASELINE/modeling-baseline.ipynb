{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5591fa98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:48.195020Z",
     "iopub.status.busy": "2022-06-29T12:40:48.194127Z",
     "iopub.status.idle": "2022-06-29T12:40:50.120415Z",
     "shell.execute_reply": "2022-06-29T12:40:50.119234Z"
    },
    "papermill": {
     "duration": 1.935657,
     "end_time": "2022-06-29T12:40:50.123452",
     "exception": false,
     "start_time": "2022-06-29T12:40:48.187795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 데이터 load & 전처리\n",
    "x_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/X_train.csv\")\n",
    "y_train = pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/y_train.csv\")\n",
    "x_test =  pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/X_test.csv\")\n",
    "y_test =  pd.read_csv(\"https://raw.githubusercontent.com/Datamanim/datarepo/main/churnk/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70e1a55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:50.133755Z",
     "iopub.status.busy": "2022-06-29T12:40:50.133338Z",
     "iopub.status.idle": "2022-06-29T12:40:50.189471Z",
     "shell.execute_reply": "2022-06-29T12:40:50.188645Z"
    },
    "papermill": {
     "duration": 0.067024,
     "end_time": "2022-06-29T12:40:50.195303",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.128279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6499 entries, 0 to 6498\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       6499 non-null   int64  \n",
      " 1   Surname          6499 non-null   object \n",
      " 2   CreditScore      6499 non-null   int64  \n",
      " 3   Geography        6499 non-null   object \n",
      " 4   Gender           6499 non-null   object \n",
      " 5   Age              6499 non-null   int64  \n",
      " 6   Tenure           6499 non-null   int64  \n",
      " 7   Balance          6499 non-null   float64\n",
      " 8   NumOfProducts    6499 non-null   int64  \n",
      " 9   HasCrCard        6499 non-null   int64  \n",
      " 10  IsActiveMember   6499 non-null   int64  \n",
      " 11  EstimatedSalary  6499 non-null   float64\n",
      "dtypes: float64(2), int64(7), object(3)\n",
      "memory usage: 609.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6499</td>\n",
       "      <td>6499</td>\n",
       "      <td>6499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2289</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Brown</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>21</td>\n",
       "      <td>3227</td>\n",
       "      <td>3485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surname Geography Gender\n",
       "count     6499      6499   6499\n",
       "unique    2289         3      4\n",
       "top      Brown    France   Male\n",
       "freq        21      3227   3485"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA 를 진행\n",
    "# 데이터 사이즈\n",
    "x_train.shape, x_train.shape\n",
    "\n",
    "# 샘플 확인\n",
    "x_train.head()\n",
    "\n",
    "# type 확인\n",
    "x_train.info()\n",
    "\n",
    "# 카테고리 수 확인\n",
    "x_train.describe(include=\"object\")\n",
    "\n",
    "# 카테고리 수 확인\n",
    "x_train.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6908b0d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:50.205785Z",
     "iopub.status.busy": "2022-06-29T12:40:50.204880Z",
     "iopub.status.idle": "2022-06-29T12:40:50.379031Z",
     "shell.execute_reply": "2022-06-29T12:40:50.377738Z"
    },
    "papermill": {
     "duration": 0.182967,
     "end_time": "2022-06-29T12:40:50.382120",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.199153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 전처리 작업공간\n",
    "# 이상치, 결측치, 피처엔지니어링\n",
    "\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "y_train = y_train['Exited']\n",
    "y_test = y_test['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ac34a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:50.391610Z",
     "iopub.status.busy": "2022-06-29T12:40:50.391144Z",
     "iopub.status.idle": "2022-06-29T12:40:50.399202Z",
     "shell.execute_reply": "2022-06-29T12:40:50.397964Z"
    },
    "papermill": {
     "duration": 0.015602,
     "end_time": "2022-06-29T12:40:50.401675",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.386073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. 모델별 스코어 및 모델 선택\n",
    "# 직접 함수를 호출해서 써도 되나 cross_val_score이 사용하기 쉬움\n",
    "# sklearn.model_selection.cross_val_score(estimator, X, y=None, scoring=None, cv=None, error_score=nan\n",
    "#                                         n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', *, groups=None)\n",
    "# 기본사용법 : estimator 확인하고자 하는 알고리즘, x값, y값, scoring 종류 선택, cv \n",
    "# scoring 사용가능 변수‘accuracy’, ‘balanced_accuracy’, ‘top_k_accuracy’\n",
    "# ‘f1’, ‘f1_micro’, ‘f1_macro’, ‘f1_weighted’, ‘f1_samples’\n",
    "# ‘roc_auc’,‘roc_auc_ovr’, ‘roc_auc_ovo’, ‘roc_auc_ovr_weighted’, ‘roc_auc_ovo_weighted’\n",
    "# ‘average_precision’, ‘neg_brier_score’\n",
    "# ‘neg_log_loss’, ‘precision’, ‘recall’, ‘jaccard’, \n",
    "# example : cross_val_score(lr_clf, x_train, x_test, cv=5, scoring='accuracy')\n",
    "\n",
    "# cross_val_score를 사용하지 않는 경우 아래와 같은 방법으로 검증해야함\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=2022)\n",
    "# X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "# 평가\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# roc_auc_score(y_val, pred[:,1])\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6b5c9",
   "metadata": {
    "papermill": {
     "duration": 0.003664,
     "end_time": "2022-06-29T12:40:50.409305",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.405641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "| Model-Classification                     | Score-Classificaiton    | Model-Regression                       | Score-Regression                      | Model-Clustring               | Score-Clustring                 |\n",
    "|------------------------------------------|-------------------------|----------------------------------------|---------------------------------------|-------------------------------|---------------------------------|\n",
    "| Logistic Regression                      | ‘accuracy’              | Linear Regression                      | ‘explained_variance’                  | K-Means                       | ‘adjusted_mutual_info_score’    |\n",
    "| Support Vector Machine                   | ‘balanced_accuracy’     | LGBM Regressor                         | ‘max_error’                           | Affinity propagation          | ‘adjusted_rand_score’           |\n",
    "| Naive Bayes (Gaussian, Multinomial)      | ‘top_k_accuracy’        | XGBoost Regressor                      | ‘neg_mean_absolute_error’             | Mean-shift                    | ‘completeness_score’            |\n",
    "| Stochastic Gradient Descent Classifier   | ‘average_precision’     | CatBoost Regressor                     | ‘neg_mean_squared_error’              | Spectral clustering           | ‘fowlkes_mallows_score’         |\n",
    "| KNN (k-nearest neighbor)                 | ‘neg_brier_score’       | Stochastic Gradient Descent Regression | ‘neg_root_mean_squared_error’         | Ward hierarchical clustering  | ‘homogeneity_score’             |\n",
    "| Decision Tree                            | ‘f1’                    | Kernel Ridge Regression                | ‘neg_mean_squared_log_error’          | Agglomerative clustering      | ‘mutual_info_score’             |\n",
    "| Random Forest                            | ‘f1_micro’              | Elastic Net Regression                 | ‘neg_median_absolute_error’           | DBSCAN                        | ‘normalized_mutual_info_score’  |\n",
    "| Gradient Boosting Classifier             | ‘f1_macro’              | Bayesian Ridge Regression              | ‘r2’                                  | OPTICS                        | ‘rand_score’                    |\n",
    "| LGBM Classifier                          | ‘f1_weighted’           | Gradient Boosting Regression           | ‘neg_mean_poisson_deviance’           | Gaussian mixtures             | ‘v_measure_score’               |\n",
    "| XGBoost Classifier                       | ‘f1_samples’            | Support Vector Machine                 | ‘neg_mean_gamma_deviance’             | BIRCH                         |                                 |\n",
    "|                                          | ‘neg_log_loss’          |                                        | ‘neg_mean_absolute_percentage_error’  | Bisecting K-Means             |                                 |\n",
    "|                                          | ‘precision’             |                                        | ‘d2_absolute_error_score’             |                               |                                 |\n",
    "|                                          | ‘recall’                |                                        | ‘d2_pinball_score’                    |                               |                                 |\n",
    "|                                          | ‘jaccard’               |                                        | ‘d2_tweedie_score’                    |                               |                                 |\n",
    "|                                          | ‘roc_auc’               |                                        |                                       |                               |                                 |\n",
    "|                                          | ‘roc_auc_ovr’           |                                        |                                       |                               |                                 |\n",
    "|                                          | ‘roc_auc_ovo’           |                                        |                                       |                               |                                 |\n",
    "|                                          | ‘roc_auc_ovr_weighted’  |                                        |                                       |                               |                                 |\n",
    "|                                          | ‘roc_auc_ovo_weighted’  |                                        |                                       |                               |                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b5d9c",
   "metadata": {
    "papermill": {
     "duration": 0.003353,
     "end_time": "2022-06-29T12:40:50.416213",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.412860",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0890c3fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:50.425459Z",
     "iopub.status.busy": "2022-06-29T12:40:50.424689Z",
     "iopub.status.idle": "2022-06-29T12:40:51.638010Z",
     "shell.execute_reply": "2022-06-29T12:40:51.636569Z"
    },
    "papermill": {
     "duration": 1.221195,
     "end_time": "2022-06-29T12:40:51.640988",
     "exception": false,
     "start_time": "2022-06-29T12:40:50.419793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 많이 쓰이는 10가지 분류모델\n",
    "# 3. 검증을 하고자 하는 모델을 몇가지 선정한 뒤 import 한다\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "lr_clf = LogisticRegression(random_state=1)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "svm = SVC(random_state=1)\n",
    "dt_clf = DecisionTreeClassifier(random_state=1)\n",
    "rf_clf = RandomForestClassifier(random_state=1)\n",
    "xgboost_clf = XGBClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b647db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:51.651156Z",
     "iopub.status.busy": "2022-06-29T12:40:51.650326Z",
     "iopub.status.idle": "2022-06-29T12:40:52.000484Z",
     "shell.execute_reply": "2022-06-29T12:40:51.999301Z"
    },
    "papermill": {
     "duration": 0.358112,
     "end_time": "2022-06-29T12:40:52.003238",
     "exception": false,
     "start_time": "2022-06-29T12:40:51.645126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 많이 쓰이는 10가지 회귀모델\n",
    "# 3. 검증을 하고자 하는 모델을 몇가지 선정한 뒤 import 한다\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65156a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:40:52.014350Z",
     "iopub.status.busy": "2022-06-29T12:40:52.012865Z",
     "iopub.status.idle": "2022-06-29T12:41:12.317180Z",
     "shell.execute_reply": "2022-06-29T12:41:12.315850Z"
    },
    "papermill": {
     "duration": 20.313236,
     "end_time": "2022-06-29T12:41:12.320533",
     "exception": false,
     "start_time": "2022-06-29T12:40:52.007297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression :  0.7962764256528689\n",
      "KNeighborsClassifier :  0.7962764256528689\n",
      "SVC :  0.7962764256528689\n",
      "DecisionTreeClassifier :  0.7962764256528689\n",
      "RandomForestClassifier :  0.7962764256528689\n",
      "XGBClassifier :  0.7962764256528689\n"
     ]
    }
   ],
   "source": [
    "# 기본적으로는 평균값으로 출력을 하나 cv 사이즈 만큼의 결과가 있기때문에 별도로 사용하는 방법을 이용해도 된다.\n",
    "# cv = cross valid며 기본적으로 계층형 k폴드형식으로 검증함\n",
    "print('LogisticRegression : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "print('KNeighborsClassifier : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "print('SVC : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "print('DecisionTreeClassifier : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "print('RandomForestClassifier : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())\n",
    "print('XGBClassifier : ', cross_val_score(lr_clf, x_train, y_train, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa05a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:41:12.339485Z",
     "iopub.status.busy": "2022-06-29T12:41:12.338848Z",
     "iopub.status.idle": "2022-06-29T12:41:12.362675Z",
     "shell.execute_reply": "2022-06-29T12:41:12.360590Z"
    },
    "papermill": {
     "duration": 0.038376,
     "end_time": "2022-06-29T12:41:12.366901",
     "exception": false,
     "start_time": "2022-06-29T12:41:12.328525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      The distance metric to use for the tree.  The default metric is\n",
      " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
      " |      metric. For a list of available metrics, see the documentation of\n",
      " |      :class:`~sklearn.metrics.DistanceMetric`.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`,\n",
      " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      Class labels known to the classifier\n",
      " |  \n",
      " |  effective_metric_ : str or callble\n",
      " |      The distance metric used. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  outputs_2d_ : bool\n",
      " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      " |      otherwise True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.666... 0.333...]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsClassifier\n",
      " |          The fitted k-nearest neighbors classifier.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 가장 마음에 드는 알고리즘을 선택한 뒤 하이퍼 파라미터를 조정한다.\n",
    "# 알고리즘에서 사용되는 파라미터를 확인하기\n",
    "# LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, \n",
    "#                     fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', \n",
    "#                     max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "print(help(KNeighborsClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4830c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:41:12.390443Z",
     "iopub.status.busy": "2022-06-29T12:41:12.389290Z",
     "iopub.status.idle": "2022-06-29T12:41:20.031431Z",
     "shell.execute_reply": "2022-06-29T12:41:20.030234Z"
    },
    "papermill": {
     "duration": 7.659999,
     "end_time": "2022-06-29T12:41:20.034810",
     "exception": false,
     "start_time": "2022-06-29T12:41:12.374811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# 사용하고자 하는 하이퍼 파라미터 알고리즘을 사용한다. 기본적으로는 gridsarch임.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_param = {\"C\":[0.5, 1.0]}\n",
    "grid_srch = GridSearchCV(lr_clf, param_grid=grid_param, scoring='accuracy', cv=5)\n",
    "grid_srch.fit(x_train, y_train)\n",
    "print(grid_srch.best_params_)\n",
    "#grid_srch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc162c73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T12:41:20.054456Z",
     "iopub.status.busy": "2022-06-29T12:41:20.053830Z",
     "iopub.status.idle": "2022-06-29T12:41:20.224920Z",
     "shell.execute_reply": "2022-06-29T12:41:20.223252Z"
    },
    "papermill": {
     "duration": 0.183572,
     "end_time": "2022-06-29T12:41:20.227084",
     "exception": true,
     "start_time": "2022-06-29T12:41:20.043512",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/148832872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# y_test값과 검증해봄...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "# 최종 모델선택과 param 선정이후 모델을 만들고 분석을 한다\n",
    "\n",
    "lr_model = LogisticRegression(random_state=1, C=0.5)\n",
    "lr.fit(x_train, y_train)\n",
    "lr.predict(x_test)\n",
    "# y_test값과 검증해봄..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.568271,
   "end_time": "2022-06-29T12:41:21.053215",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-29T12:40:38.484944",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
