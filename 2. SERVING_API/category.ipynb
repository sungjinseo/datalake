{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubeflow Pipelines e2e mnist example\n",
    "\n",
    "In this notebook you will create e2e mnist Kubeflow Pipeline to perform:\n",
    "- Hyperparameter tuning using Katib\n",
    "- Distributive training with the best hyperparameters using TFJob\n",
    "- Serve the trained model using KServe\n",
    "\n",
    "Reference documentation:\n",
    "\n",
    "- https://www.kubeflow.org/docs/components/training/tftraining/\n",
    "- https://www.kubeflow.org/docs/components/katib/\n",
    "- https://www.kubeflow.org/docs/external-add-ons/kserve/\n",
    "\n",
    "**Note**: This Pipeline runs in the multi-user mode. Follow [this guide](https://www.kubeflow.org/docs/components/pipelines/sdk/connect-api/#multi-user-mode) to give your Notebook access to Kubeflow Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp import components\n",
    "\n",
    "from kubeflow.katib import ApiClient\n",
    "from kubeflow.katib import V1beta1ExperimentSpec\n",
    "from kubeflow.katib import V1beta1AlgorithmSpec\n",
    "from kubeflow.katib import V1beta1ObjectiveSpec\n",
    "from kubeflow.katib import V1beta1ParameterSpec\n",
    "from kubeflow.katib import V1beta1FeasibleSpace\n",
    "from kubeflow.katib import V1beta1TrialTemplate\n",
    "from kubeflow.katib import V1beta1TrialParameterSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Pipelines tasks\n",
    "\n",
    "To run this Pipeline, you should define:\n",
    "1. Katib hyperparameter tuning\n",
    "2. TFJob training\n",
    "3. KServe inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Katib hyperparameter tuning task\n",
    "\n",
    "Create the Kubeflow Pipelines task for the Katib hyperparameter tuning. This Experiment uses \"random\" algorithm and TFJob for the Trial's worker.\n",
    "\n",
    "The Katib Experiment is similar to this example: https://github.com/kubeflow/katib/blob/master/examples/v1beta1/kubeflow-training-operator/tfjob-mnist-with-summaries.yaml."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. TFJob training task\n",
    "\n",
    "Create the Kubeflow Pipelines task for the TFJob training. In this example TFJob runs the Chief and Worker with 1 replica.\n",
    "\n",
    "Learn more about TFJob replica specifications in the Kubeflow docs: https://www.kubeflow.org/docs/components/training/tftraining/#what-is-tfjob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should define the TFJob name, namespace, number of training steps, output of Katib and model volume tasks in the arguments.\n",
    "def create_tfjob_task(tfjob_name, tfjob_namespace, training_steps, model_volume_op):\n",
    "    import json\n",
    "    # Get parameters from the Katib Experiment.\n",
    "    # Parameters are in the format \"--tf-learning-rate=0.01 --tf-batch-size=100\"\n",
    "    #convert_katib_results_op = components.func_to_container_op(convert_katib_results)\n",
    "    #best_hp_op = convert_katib_results_op(katib_op.output)\n",
    "    #best_hps = str(best_hp_op.output)\n",
    "\n",
    "    # Create the TFJob Chief and Worker specification with the best Hyperparameters.\n",
    "    # TODO (andreyvelich): Use community image for the mnist example.\n",
    "    tfjob_chief_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/sjseo85/category-model:1.6\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\"\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                            \"python /app/category_classification.py --tf-export-dir=/mnt/models/1 --tf-train-steps={} {}\".format(1, 1)\n",
    "                        ],\n",
    "                        \"volumeMounts\": [\n",
    "                            {\n",
    "                                \"mountPath\": \"/mnt/models\",\n",
    "                                \"name\": \"model-volume\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"volumes\": [\n",
    "                    {\n",
    "                        \"name\": \"model-volume\",\n",
    "                        \"persistentVolumeClaim\": {\n",
    "                            \"claimName\": str(model_volume_op.outputs[\"name\"])\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tfjob_worker_spec = {\n",
    "        \"replicas\": 1,\n",
    "        \"restartPolicy\": \"OnFailure\",\n",
    "        \"template\": {\n",
    "            \"metadata\": {\n",
    "                \"annotations\": {\n",
    "                    \"sidecar.istio.io/inject\": \"false\"\n",
    "                }\n",
    "            },\n",
    "            \"spec\": {\n",
    "                \"containers\": [\n",
    "                    {\n",
    "                        \"name\": \"tensorflow\",\n",
    "                        \"image\": \"docker.io/sjseo85/category-model:1.6\",\n",
    "                        \"command\": [\n",
    "                            \"sh\",\n",
    "                            \"-c\",\n",
    "                        ],\n",
    "                        \"args\": [\n",
    "                          \"python /app/category_classification.py --tf-export-dir=/mnt/models/1 --tf-train-steps={} {}\".format(1, 1) \n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create the KFP task for the TFJob.\n",
    "    tfjob_launcher_op = components.load_component_from_url(\n",
    "        \"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/launcher/component.yaml\")\n",
    "    op = tfjob_launcher_op(\n",
    "        name=tfjob_name,\n",
    "        namespace=tfjob_namespace,\n",
    "        chief_spec=json.dumps(tfjob_chief_spec),\n",
    "        worker_spec=json.dumps(tfjob_worker_spec),\n",
    "        tfjob_timeout_minutes=60,\n",
    "        delete_finished_tfjob=False)\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. KServe inference\n",
    "\n",
    "Create the Kubeflow Pipelines task for the KServe inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_serving_task(model_name, model_namespace, tfjob_op, model_volume_op):\n",
    "\n",
    "    api_version = 'serving.kserve.io/v1beta1'\n",
    "    serving_component_url = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kserve/component.yaml'\n",
    "\n",
    "    # Uncomment the following two lines if you are using KFServing v0.6.x or v0.5.x\n",
    "    # api_version = 'serving.kubeflow.org/v1beta1'\n",
    "    # serving_component_url = 'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/kfserving/component.yaml'\n",
    "\n",
    "    inference_service = '''\n",
    "apiVersion: \"{}\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: {}\n",
    "  namespace: {}\n",
    "  annotations:\n",
    "    \"sidecar.istio.io/inject\": \"false\"\n",
    "spec:\n",
    "  predictor:\n",
    "    tensorflow:\n",
    "      storageUri: \"pvc://{}/\"\n",
    "'''.format(api_version, model_name, model_namespace, str(model_volume_op.outputs[\"name\"]))\n",
    "\n",
    "    serving_launcher_op = components.load_component_from_url(serving_component_url)\n",
    "    serving_launcher_op(action=\"apply\", inferenceservice_yaml=inference_service).after(tfjob_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Kubeflow Pipeline\n",
    "\n",
    "You should create the Kubeflow Pipeline from the above tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/9a931cf3-40eb-43eb-af12-449c399b46d6\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/ba812e4d-079b-49a7-bb9b-d076ff74725f\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID:  ba812e4d-079b-49a7-bb9b-d076ff74725f\n"
     ]
    }
   ],
   "source": [
    "name=\"category-e2e-v4\"\n",
    "namespace=\"kubeflow-user-example-com\"\n",
    "training_steps=\"100\"\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=\"End to End Pipeline\",\n",
    "    description=\"An end to end mnist example including train and inference\"\n",
    ")\n",
    "def category_pipeline(name=name, namespace=namespace, training_steps=training_steps):\n",
    "    # Run the hyperparameter tuning with Katib.\n",
    "    #katib_op = create_katib_experiment_task(name, namespace, training_steps)\n",
    "\n",
    "    # Create volume to train and serve the model.\n",
    "    model_volume_op = dsl.VolumeOp(\n",
    "        name=\"model-volume\",\n",
    "        resource_name=\"model-volume\",\n",
    "        size=\"1Gi\",\n",
    "        modes=dsl.VOLUME_MODE_RWO\n",
    "    )\n",
    "\n",
    "    # Run the distributive training with TFJob.\n",
    "    tfjob_op = create_tfjob_task(name, namespace, training_steps, model_volume_op)\n",
    "\n",
    "    # Create the KServe inference.\n",
    "    create_serving_task(name, namespace, tfjob_op, model_volume_op)\n",
    "# Run the Kubeflow Pipeline in the user's namespace.\n",
    "\n",
    "kfp_client=kfp.Client()\n",
    "run_id = kfp_client.create_run_from_pipeline_func(category_pipeline, namespace=namespace, arguments={}).run_id\n",
    "print(\"Run ID: \", run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict from the trained model\n",
    "\n",
    "Once Kubeflow Pipeline is finished, you are able to call the API endpoint with [mnist image](https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/kubeflow-pipelines/images/9.bmp) to predict from the trained model.\n",
    "\n",
    "**Note**: If you are using Kubeflow + Dex setup and runing this Notebook outside of your Kubernetes cluster, follow [this guide](https://github.com/kserve/kserve/tree/master/docs/samples/istio-dex#authentication) to get Session ID for the API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ba812e4d-079b-49a7-bb9b-d076ff74725f has been Succeeded\n",
      "\n",
      "http://category-e2e-v4-predictor-default.kubeflow-user-example-com.svc.cluster.local/v1/models/category-e2e-v4:predict\n",
      "Prediction for the image\n",
      "{'predictions': [[0.00177408778, 0.00279735844, 0.00949931704, 0.00425323658, 0.00897183, 0.0152991116, 0.0113294674, 0.00479388749, 0.00690608, 0.0112169767, 0.00591368508, 0.00538556371, 0.00743126357, 0.00549162785, 0.0060344981, 0.00549076078, 0.0107562067, 0.0113362083, 0.0115286559, 0.00831412524, 0.0154880313, 0.00836658105, 0.00604901789, 0.00607525278, 0.011491931, 0.0101766856, 0.00667964667, 0.00838674605, 0.01140083, 0.00741297845, 0.0102966791, 0.00940914638, 0.00511750113, 0.00916701555, 0.00449514296, 0.0111307, 0.00605040928, 0.00642242283, 0.00648104772, 0.00858241785, 0.0126806693, 0.00433605397, 0.00526441121, 0.00459282193, 0.00922197849, 0.0123699559, 0.00613749167, 0.00869658496, 0.00440196833, 0.0110856593, 0.00883079413, 0.00710960617, 0.00805666484, 0.0120763136, 0.0112289833, 0.00868634321, 0.0110943131, 0.00930569787, 0.0112451147, 0.0107136285, 0.00926313829, 0.0039129043, 0.00580092659, 0.0101137795, 0.0062568672, 0.0124158114, 0.00631166436, 0.0064888522, 0.00492085423, 0.00839012302, 0.00633551646, 0.0103662377, 0.00232555694, 0.0125559112, 0.00682554767, 0.00598323904, 0.00481805345, 0.00891212281, 0.012929921, 0.00553301023, 0.00266500306, 0.0144431638, 0.010234382, 0.0115474127, 0.0102564236, 0.0113160303, 0.00973199215, 0.00770820072, 0.011608839, 0.00708045391, 0.00749536371, 0.010439828, 0.00699266465, 0.00825282652, 0.0092612952, 0.0101032043, 0.00770203164, 0.00290001603, 0.0101932855, 0.00943678524, 0.0103783906, 0.0114184935, 0.00667650066, 0.0126219941, 0.0101161366, 0.008085059, 0.0037398, 0.008709874, 0.00359174283, 0.00959909428, 0.00847516209, 0.00499888323, 0.00743199699, 0.00918123592, 0.00863876753, 0.00408575358, 0.00659036497, 0.00215621898, 0.00323822536, 0.00945589412, 0.0100757889, 0.00225947262, 0.00830669329]]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Pipeline Run should be succeeded.\n",
    "kfp_run = kfp_client.get_run(run_id=run_id)\n",
    "if kfp_run.run.status == \"Succeeded\":\n",
    "    print(\"Run {} has been Succeeded\\n\".format(run_id))\n",
    "\n",
    "    # Specify the image URL here.\n",
    "    #image_url = \"https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/kubeflow-pipelines/images/9.bmp\"\n",
    "    #image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "    #data = np.array(image.convert('L').resize((28, 28))).astype(np.float).reshape(-1, 28, 28, 1)\n",
    "    #data_formatted = np.array2string(data, separator=\",\", formatter={\"float\": lambda x: \"%.1f\" % x})\n",
    "    #json_request = '{{ \"instances\" : {} }}'.format([[1, 2, 3, 4, 5, 2, 3, 4, 5, 2, 6]])\n",
    "    json_request = {\"instances\":[[1,2,3,4]]}\n",
    "\n",
    "    # Specify the prediction URL. If you are runing this notebook outside of Kubernetes cluster, you should set the Cluster IP.\n",
    "    url = \"http://{}-predictor-default.{}.svc.cluster.local/v1/models/{}:predict\".format(name, namespace, name)\n",
    "    print(url)\n",
    "    #response = requests.post(url, data=json_request)\n",
    "    \n",
    "    r = requests.post(url=\"http://{}-predictor-default.{}.svc.cluster.local/v1/models/{}:predict\".format(name, namespace, name), data=json.dumps(json_request))\n",
    "    \n",
    "    print(\"Prediction for the image\")\n",
    "    #display(image)\n",
    "    print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
